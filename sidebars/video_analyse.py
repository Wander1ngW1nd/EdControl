# -*- coding: utf-8 -*-
"""
Created on Tue Sep  5 23:45:21 2023

@author: M
"""
import cv2
import emrec_model as EM
import glob
import streamlit as st
import os

from plotlycharts import charts


#VIDEO_PATH = "C:\\Users\\–ü–ö\\Videos"

README_IMG_FOLDER = "img"
README_FILE_PATH = "Readme_for_main_page.txt"

EMOTIONS_RU = {"angry":"–ó–ª–æ—Å—Ç—å", "disgust":"–û—Ç–≤—Ä–∞—â–µ–Ω–∏–µ", "fear":"–°—Ç—Ä–∞—Ö",
            "happy":"–°—á–∞—Å—Ç—å–µ", "sad":"–ì—Ä—É—Å—Ç—å", "surprise":"–£–¥–∏–≤–ª–µ–Ω–∏–µ"}

def draw_readme(column):
    print(os.listdir("."))
    with open(README_FILE_PATH, 'r') as f:
        readme_line = f.readlines()
        buffer = []
        resourses = [os.path.basename(x) for x in glob.glob(README_IMG_FOLDER + "//*")]
    for line in readme_line:
        buffer.append(line)
        for imgFolder in resourses:
            if imgFolder in line:
                column.markdown(''.join(buffer[:-1])) 
                column.image(os.path.join(README_IMG_FOLDER, imgFolder), use_column_width = True)
                buffer.clear()
    column.markdown(''.join(buffer))

def seconds_to_time(seconds):
    
    seconds = seconds % (24 * 3600)
    hour = seconds // 3600
    seconds %= 3600
    minutes = seconds // 60
    seconds %= 60
    time = "%d:%02d:%02d" % (hour, minutes, seconds) 
     
    return time

def count_video_length(path, name):
    
    path_to_video = os.path.join(path, name)
    cap = cv2.VideoCapture(path_to_video)
    fps = cap.get(cv2.CAP_PROP_FPS) 
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count/fps
    length = duration / 60  # duration in minutes
    
    return length

#—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —ç–∫—Å–ø–∞–Ω–¥–µ—Ä–æ–≤ –¥–æ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–∏–¥–µ–æ, –∞—Ä–≥—É–º–µ–Ω—Ç - –∫–æ–ª–æ–Ω–∫–∞, –≤ –∫–æ—Ç–æ—Ä–æ–π –≤—Å–µ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è
def default_expanders(teacher):

    with teacher.expander(":red[–§–ò–û_–¥–∞—Ç–∞_–≤—Ä–µ–º—è1.mp4]"):
        st.write("...")
    with teacher.expander(":green[–§–ò–û_–¥–∞—Ç–∞_–≤—Ä–µ–º—è1.mp4]"):
        st.write("...")
    with teacher.expander(":orange[–§–ò–û_–¥–∞—Ç–∞_–≤—Ä–µ–º—è1.mp4]"):
        st.write("...")

#—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —ç–∫—Å–ø–∞–Ω–¥–µ—Ä–æ–≤ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–∏–¥–µ–æ, –∞—Ä–≥—É–º–µ–Ω—Ç—ã-–∫–æ–ª–æ–Ω–∫–∞ –∏ –≤–∏–¥–µ–æ—Ñ–∞–π–ª
def add_expander(teacher, video, path, data):


    with teacher.expander(":green[–∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –≤–∏–¥–µ–æ]"):
        st.write("–ê–Ω–∞–ª–∏—Ç–∏–∫–∞")
        info, timeStamps = st.columns([4, 6])

   #video read
        video_file = open(os.path.join(path, video.name), 'rb')
        video_bytes = video_file.read()
        #info.write("videoplayer")
        info.video(video_bytes)

        timeStamps.text("–í—Ä–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ—Ç–º–µ—Ç–∫–∏ ‚¨á")
        
        
        
        stampData = [{"–≤—Ä–µ–º—è": "5:10", "–≠–º–æ—Ü–∏—è":"–£–¥–∏–≤–ª–µ–Ω–∏–µ"},
                {"–≤—Ä–µ–º—è": "8:09", "–≠–º–æ—Ü–∏—è":"–ì—Ä—É—Å—Ç—å"},
                {"–≤—Ä–µ–º—è": "11:14", "–≠–º–æ—Ü–∏—è":"–°—á–∞—Å—Ç—å–µ"}]
        
        timeStamps.data_editor(stampData, disabled = True)

        
        #selectbox –≤—ã–±–æ—Ä–∞ —Ç–∏–ø–∞ –≥—Ä–∞—Ñ–∏–∫–∞
        

       
        radio = charts.radio_chart(data)
        info.plotly_chart(radio, use_container_width=True)
       
        bar = charts.bar_chart(data)
        info.plotly_chart(bar, use_container_width=True)
      

    with teacher.expander(":red[–§–ò–û_–¥–∞—Ç–∞_–≤—Ä–µ–º—è1.mp4]"):
        st.write("...")
    with teacher.expander(":green[–§–ò–û_–¥–∞—Ç–∞_–≤—Ä–µ–º—è1.mp4]"):
        st.write("...")
    with teacher.expander(":orange[–§–ò–û_–¥–∞—Ç–∞_–≤—Ä–µ–º—è1.mp4]"):
        st.write("...")

#view, –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º–∞—è –ø–æ –Ω–∞–∂–∞—Ç–∏—é –Ω–∞ –ø—Ä–µ–ø–æ–¥–∞
def view_side_bar(name, teacher, path):
    teacher.header("üì∏"+name)

    rating, info = teacher.columns([3,5])

    rating.header("–†–µ–π—Ç–∏–Ω–≥")
    rating.text("‚≠ê‚≠ê‚≠ê")

    info.header("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
    info.text("email, phone")

    #upload —Ñ–∞–π–ª–∞
    videoFile = teacher.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–¥–µ–æ", type='mp4',\
                                      accept_multiple_files=False)
    
    
    #–µ—Å–ª–∏ –≤–∏–¥–µ–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –æ—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –±–æ–ª—å—à–µ —ç–∫—Å–ø–∞–Ω–¥–µ—Ä–æ–≤
    if videoFile is not None:
        

        #—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –≤ –¥–∏—Ä—Ä–µ–∫—Ç–æ—Ä–∏—é
        with open(os.path.join(path, videoFile.name),"wb") as f:
            f.write(videoFile.getbuffer())
        videoLength = count_video_length(path, videoFile.name)
        if videoLength <=5 and videoLength >= 0.01:
            with teacher.status("–û–±—Ä–∞–±–æ—Ç–∫–∞"):
                model = EM.VideoEmotionRecognizer(os.path.join(path, videoFile.name))
                outputSummary = model.emotions_summary()
                
                ruData = {}
                for key, value in outputSummary.items():
                    ruData[EMOTIONS_RU[key]] = value
                
            teacher.header("–í—ã–±–æ—Ä –≤–∏–¥–µ–æ")
            add_expander(teacher, videoFile, path, ruData)
        else:
            teacher.error("–î–ª–∏–Ω–Ω–æ–µ –≤–∏–¥–µ–æ")
            teacher.header("–í—ã–±–æ—Ä —É—Ä–æ–∫–∞")
            default_expanders(teacher)
    #–∏–Ω–∞—á–µ –æ—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∫–æ–ª-–≤–æ —ç–∫—Å–ø–∞–Ω–¥–µ—Ä–æ–≤
    else:
        
        teacher.header("–í—ã–±–æ—Ä –≤–∏–¥–µ–æ")

        default_expanders(teacher)
